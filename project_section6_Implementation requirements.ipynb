{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ce5c40",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">6. Implementation requirements </span> <a id='6.'></a>\n",
    "\n",
    "### <span style=\"color:red\">Your implemented algorithm must be compatible with the below requirements; otherwise, the code will be considered invalid.</span>\n",
    "\n",
    "## I. Data Saving Format\n",
    "\n",
    "### a) Training Logs: \n",
    "During the training, your code shall create a CSV file as the training log.\n",
    "\n",
    "  - This log should output a CSV file with the following format:\n",
    "    ```\n",
    "    ,episode_length,ep_reward,episodes,total_step,average_return\n",
    "    0,20,0.0,99,2000,-0.13\n",
    "    1,20,0.0,199,4000,0.02\n",
    "    ...\n",
    "    ```\n",
    "  - The training log should be saved as:\n",
    "    `results/<environment name>/<algorithm name>/logging/logs_<seed number>.csv`\n",
    "    \n",
    "    For example:\n",
    "    `results/SandingEnvDifficult/ddpg/logging/logs_0.csv`\n",
    "    \n",
    "\n",
    "### b) Model Weights\n",
    "\n",
    "During/after training, the policy/critic weights should be saved in the path:\n",
    "\n",
    "  `results/<environment name>/<algorithm name>/model/model_parameters_<seed number>.pt`\n",
    "  \n",
    "  For example:\n",
    "  \n",
    "  `results/SandingEnvDifficult/ddpg/model/model_parameters_0.pt`\n",
    "\n",
    "### c) Videos: \n",
    "\n",
    "Training videos will automatically be saved under path `results/<environment name>/<algorithm name>/video/train`. Note that you do not need to implement this.\n",
    "\n",
    "\n",
    "\n",
    "## II. Visualization Plot Functions\n",
    "\n",
    "Ensure that your implemented algorithm is compatible with the functions located in `utils/common_utils.py`:\n",
    "\n",
    "- **Single Training Curve**: \n",
    "  - Function: `plot_reward(path, seed, env_name)`\n",
    "  - Description: Plots the training curve of a single algorithm, trained with a specific seed.\n",
    "  \n",
    "- **Multiple Training Curves**: \n",
    "  - Function: `plot_algorithm_training(path, seeds, env_name)`\n",
    "  - Description: Plots the training curves of a single algorithm, trained with multiple specific random seeds.\n",
    "  - Example: `seeds=[0,1,2]`\n",
    "  \n",
    "- **Comparison of Training Performances**: \n",
    "  - Function: `compare_algorithm_training(algo1, algo2, seeds)`\n",
    "  - Description: Given two configured algorithms/agents, this function will generate comparison plots of their training performances.\n",
    "\n",
    "\n",
    "## III. <span style=\"color:red\"> Configurations </span>\n",
    "\n",
    "We provide the hyperparameters in 'cfg/algo', use those configuration files to initialize your agent. Example refer to following code. You should not change any parameters there.\n",
    "\n",
    "**Usage Example**:\n",
    "```python\n",
    "config = setup(algo='ppo', env='middle')\n",
    "    config[\"seed\"] = 0\n",
    "    agent = PPOAgent(config)\n",
    "```\n",
    "\n",
    "## IV. <span style=\"color:red\"> Training implementation </span>\n",
    "\n",
    "To ensure compatibility with the setup function, your implemented algorithm must follow the specified protocol:\n",
    "\n",
    "- **Function**: `setup(algo=None, env='easy', cfg_args={})`\n",
    "  - **Purpose**: Used for setting up the configurations.\n",
    "  - **Usage Example**:\n",
    "    ```python\n",
    "    config = setup(algo='ppo', env='middle')\n",
    "    config[\"seed\"] = 0\n",
    "    agent = PPOAgent(config)\n",
    "    agent.train()\n",
    "    ```\n",
    "  - **Parameters**:\n",
    "    - `algo`: Specify the algorithm. Use either `'ppo'` or `'ddpg'`.\n",
    "    - `env`: Specify the environment. Options include `'easy'`, `'middle'`, or `'difficult'`.\n",
    "\n",
    "## V. <span style=\"color:red\"> Test implementation </span>\n",
    "\n",
    "To ensure compatibility with the setup function, your implemented algorithm must follow the specified protocol:\n",
    "\n",
    "- **Function**: `test`\n",
    "  - **Purpose**: Used for test the performance of the agent.\n",
    "  - **Usage Example**:\n",
    "    ```python\n",
    "    test(agent, env_name='easy', algo_name='ddpg')\n",
    "    ```\n",
    "\n",
    "## VI. <span style=\"color:red\"> Access </span>\n",
    "\n",
    "You should not modify any files in paths:\n",
    "- 'cfg/'\n",
    "- 'utils/'\n",
    "- 'sanding.py'\n",
    "\n",
    "## VI. <span style=\"color:red\"> Other tips </span>\n",
    "\n",
    "1. If you choose DDPG based on ex6, you should be careful with function 'get_action()'. You should not use \n",
    "```python\n",
    "    if self.buffer_ptr < self.random_transition:\n",
    "``` \n",
    "if you want to evaluate the agent's performance when using:\n",
    "```python\n",
    "test(agent, env_name='easy', algo_name='ddpg')\n",
    "```\n",
    "\n",
    "2. The standard deviation of gaussian policy in PPO is crucial for performance.\n",
    "\n",
    "### <span style=\"color:red\">Your implemented algorithm must be compatible with the above requirements; otherwise, the code will be considered invalid.</span>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
